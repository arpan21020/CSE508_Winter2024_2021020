{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset:\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568449</th>\n",
       "      <td>568450</td>\n",
       "      <td>B001EO7N10</td>\n",
       "      <td>A28KG5XORO54AY</td>\n",
       "      <td>Lettie D. Carter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1299628800</td>\n",
       "      <td>Will not do without</td>\n",
       "      <td>Great for sesame chicken..this is a good if no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568450</th>\n",
       "      <td>568451</td>\n",
       "      <td>B003S1WTCU</td>\n",
       "      <td>A3I8AFVPEE8KI5</td>\n",
       "      <td>R. Sawyer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1331251200</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>I'm disappointed with the flavor. The chocolat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568451</th>\n",
       "      <td>568452</td>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A121AA1GQV751Z</td>\n",
       "      <td>pksd \"pk_007\"</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1329782400</td>\n",
       "      <td>Perfect for our maltipoo</td>\n",
       "      <td>These stars are small, so you can give 10-15 o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568452</th>\n",
       "      <td>568453</td>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A3IBEVCTXKNOH</td>\n",
       "      <td>Kathy A. Welch \"katwel\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1331596800</td>\n",
       "      <td>Favorite Training and reward treat</td>\n",
       "      <td>These are the BEST treats for training and rew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568453</th>\n",
       "      <td>568454</td>\n",
       "      <td>B001LR2CU2</td>\n",
       "      <td>A3LGQPJCZVL9UC</td>\n",
       "      <td>srfell17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1338422400</td>\n",
       "      <td>Great Honey</td>\n",
       "      <td>I am very satisfied ,product is as advertised,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>568454 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId                      ProfileName  \\\n",
       "0            1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1            2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2            3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3            4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4            5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "...        ...         ...             ...                              ...   \n",
       "568449  568450  B001EO7N10  A28KG5XORO54AY                 Lettie D. Carter   \n",
       "568450  568451  B003S1WTCU  A3I8AFVPEE8KI5                        R. Sawyer   \n",
       "568451  568452  B004I613EE  A121AA1GQV751Z                    pksd \"pk_007\"   \n",
       "568452  568453  B004I613EE   A3IBEVCTXKNOH          Kathy A. Welch \"katwel\"   \n",
       "568453  568454  B001LR2CU2  A3LGQPJCZVL9UC                         srfell17   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                          1                       1      5  1303862400   \n",
       "1                          0                       0      1  1346976000   \n",
       "2                          1                       1      4  1219017600   \n",
       "3                          3                       3      2  1307923200   \n",
       "4                          0                       0      5  1350777600   \n",
       "...                      ...                     ...    ...         ...   \n",
       "568449                     0                       0      5  1299628800   \n",
       "568450                     0                       0      2  1331251200   \n",
       "568451                     2                       2      5  1329782400   \n",
       "568452                     1                       1      5  1331596800   \n",
       "568453                     0                       0      5  1338422400   \n",
       "\n",
       "                                   Summary  \\\n",
       "0                    Good Quality Dog Food   \n",
       "1                        Not as Advertised   \n",
       "2                    \"Delight\" says it all   \n",
       "3                           Cough Medicine   \n",
       "4                              Great taffy   \n",
       "...                                    ...   \n",
       "568449                 Will not do without   \n",
       "568450                        disappointed   \n",
       "568451            Perfect for our maltipoo   \n",
       "568452  Favorite Training and reward treat   \n",
       "568453                         Great Honey   \n",
       "\n",
       "                                                     Text  \n",
       "0       I have bought several of the Vitality canned d...  \n",
       "1       Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2       This is a confection that has been around a fe...  \n",
       "3       If you are looking for the secret ingredient i...  \n",
       "4       Great taffy at a great price.  There was a wid...  \n",
       "...                                                   ...  \n",
       "568449  Great for sesame chicken..this is a good if no...  \n",
       "568450  I'm disappointed with the flavor. The chocolat...  \n",
       "568451  These stars are small, so you can give 10-15 o...  \n",
       "568452  These are the BEST treats for training and rew...  \n",
       "568453  I am very satisfied ,product is as advertised,...  \n",
       "\n",
       "[568454 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568411, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/najiya/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/najiya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/najiya/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    # Lowercasing\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    # Join tokens back into a string\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_207442/2285386154.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['combined'] = df['Text']  + 'TL;DR' + df['Summary']\n"
     ]
    }
   ],
   "source": [
    "# Combining the two columns review and summary:\n",
    "df['combined'] = df['Text']  + 'TL;DR' + df['Summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews = df.head(50000)\n",
    "reviews=df\n",
    "reviews= reviews['combined'].tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/najiya/anaconda3/lib/python3.9/site-packages/transformers/models/auto/modeling_auto.py:1699: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing the dataset into training and testing (75:25) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode(\" TL;DR \")\n",
    "extra_length = len(tokenizer.encode(\" TL;DR \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Data Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPT2ReviewDataset(Dataset):\n",
    "    def __init__(self, tokenizer, reviews, max_len):\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "        self.eos = self.tokenizer.eos_token\n",
    "        self.eos_id = self.tokenizer.eos_token_id\n",
    "        self.reviews = reviews\n",
    "        self.result = []\n",
    "\n",
    "        for review in self.reviews:\n",
    "            # Encode the text using tokenizer.encode(). We add EOS at the end\n",
    "            tokenized = self.tokenizer.encode(review + self.eos, truncation=True, max_length=self.max_len)\n",
    "\n",
    "            # Padding/truncating the encoded sequence to max_len\n",
    "            padded = self.pad_truncate(tokenized)\n",
    "\n",
    "            # Creating a tensor and adding to the result\n",
    "            self.result.append(torch.tensor(padded, dtype=torch.long))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.result)\n",
    "\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.result[item]\n",
    "\n",
    "    def pad_truncate(self, name):\n",
    "\n",
    "        name_length = len(name) - extra_length\n",
    "        if name_length < self.max_len:\n",
    "            difference = self.max_len - name_length\n",
    "            result = name + [self.eos_id] * difference\n",
    "        elif name_length > self.max_len:\n",
    "            result = name[:self.max_len + 3]+[self.eos_id]\n",
    "        else:\n",
    "            result = name\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 100\n",
    "reviews_dataset = GPT2ReviewDataset(tokenizer, reviews, max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(reviews_dataset, batch_size=32, shuffle=True,drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning the GPT-2 model on the review dataset to generate summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, dl, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch :\",(epoch+1))\n",
    "        for idx, batch in enumerate(dl):\n",
    "             with torch.set_grad_enabled(True):\n",
    "                optimizer.zero_grad()\n",
    "                batch = batch.to(device)\n",
    "                output = model(batch, labels=batch)\n",
    "                loss = output[0]\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                if idx % 5000 == 0:\n",
    "                    # print(\"loss: %f\"%(loss))\n",
    "                    print(f\"loss: {loss}, {idx}\")\n",
    "    torch.save(model.state_dict(), 'model_completeDataset.pth')  # Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 6.765002727508545, 0\n",
      "loss: 2.2353031635284424, 5000\n",
      "loss: 2.0522336959838867, 10000\n",
      "loss: 1.942301630973816, 15000\n",
      "Epoch : 2\n",
      "loss: 1.8105591535568237, 0\n",
      "loss: 1.8702399730682373, 5000\n",
      "loss: 1.4940941333770752, 10000\n",
      "loss: 1.5958985090255737, 15000\n",
      "Epoch : 3\n",
      "loss: 1.5737464427947998, 0\n",
      "loss: 1.3289415836334229, 5000\n",
      "loss: 1.408329963684082, 10000\n",
      "loss: 1.3203850984573364, 15000\n",
      "Epoch : 4\n",
      "loss: 1.3660566806793213, 0\n",
      "loss: 1.6720166206359863, 5000\n",
      "loss: 1.543911099433899, 10000\n",
      "loss: 1.6843066215515137, 15000\n",
      "Epoch : 5\n",
      "loss: 1.0744960308074951, 0\n",
      "loss: 1.0217071771621704, 5000\n",
      "loss: 1.4755713939666748, 10000\n",
      "loss: 1.2410725355148315, 15000\n"
     ]
    }
   ],
   "source": [
    "train(model=model, optimizer=optimizer, dl=dataloader, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk(probs, n=9):\n",
    "    # The scores are initially softmaxed to convert to probabilities\n",
    "    probs = torch.softmax(probs, dim= -1)\n",
    "\n",
    "    # PyTorch has its own topk method, which we use here\n",
    "    tokensProb, topIx = torch.topk(probs, k=n)\n",
    "\n",
    "    # The new selection pool (9 choices) is normalized\n",
    "    tokensProb = tokensProb / torch.sum(tokensProb)\n",
    "\n",
    "    # Send to CPU for numpy handling\n",
    "    tokensProb = tokensProb.cpu().detach().numpy()\n",
    "\n",
    "    # Make a random choice from the pool based on the new prob distribution\n",
    "    choice = np.random.choice(n, 1, p = tokensProb)\n",
    "    tokenId = topIx[choice][0]\n",
    "\n",
    "    return int(tokenId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_infer(model, tokenizer, review, max_length=15):\n",
    "    # Preprocess the init token (task designator)\n",
    "    review_encoded = tokenizer.encode(review)\n",
    "    result = review_encoded\n",
    "    initial_input = torch.tensor(review_encoded).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        # Feed the init token to the model\n",
    "        output = model(initial_input)\n",
    "\n",
    "        # Flatten the logits at the final time step\n",
    "        logits = output.logits[0,-1]\n",
    "\n",
    "        # Make a top-k choice and append to the result\n",
    "        result.append(topk(logits))\n",
    "\n",
    "        # For max_length times:\n",
    "        for _ in range(max_length):\n",
    "            # Feed the current sequence to the model and make a choice\n",
    "            input = torch.tensor(result).unsqueeze(0).to(device)\n",
    "            output = model(input)\n",
    "            logits = output.logits[0,-1]\n",
    "            res_id = topk(logits)\n",
    "\n",
    "            # If the chosen token is EOS, return the result\n",
    "            if res_id == tokenizer.eos_token_id:\n",
    "                return tokenizer.decode(result)\n",
    "            else: # Append to the sequence\n",
    "                result.append(res_id)\n",
    "    # IF no EOS is generated, return after the max_len\n",
    "    return tokenizer.decode(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"gpt2\")\n",
    "model.load_state_dict(torch.load('model50000.pth'))  # Load the saved model\n",
    "# model.eval()  # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Given_Review_Text =  \"The Fender CD-60S Dreadnought Acoustic Guitar is a great instrument for beginners. It has a solid construction, produces a rich sound, and feels comfortable to play. However, some users have reported issues with the tuning stability.\"\n",
    "# Given_Review_Text=input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Given_Summary = \"Good for beginners but has tuning stability issues.\"\n",
    "# Given_Summary=input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary : Great Guitar for Beginner\n"
     ]
    }
   ],
   "source": [
    "\n",
    "generated_summary = model_infer(model, tokenizer, Given_Review_Text + \" TL;DR \").split(\" TL;DR \")[1].strip()\n",
    "print(\"Generated Summary :\",generated_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge Scores\n",
      "ROUGE-1 : Precision:0.25, Recall :0.125, F1-Score :0.16666666222222234\n",
      "ROUGE-2 : Precision:0.0, Recall :0.0, F1-Score:0.0\n",
      "ROUGE-l : Precision:0.25, Recall :0.125, F1-Score:0.16666666222222234\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "# Initialize Rouge\n",
    "rouge = Rouge()\n",
    "\n",
    "# Assuming you have generated summaries and actual summaries\n",
    "generated_summaries = [generated_summary]  # Replace [...] with your generated summaries\n",
    "actual_summaries = [Given_Summary]     # Replace [...] with your actual summaries\n",
    "\n",
    "# Compute ROUGE scores\n",
    "scores = rouge.get_scores(generated_summaries, actual_summaries, avg=False)[0]\n",
    "\n",
    "# Print ROUGE scores\n",
    "print(\"Rouge Scores\")\n",
    "# print(scores)\n",
    "print(f\"ROUGE-1 : Precision:{scores['rouge-1']['p']}, Recall :{scores['rouge-1']['r']}, F1-Score :{scores['rouge-1']['f']}\")\n",
    "print(f\"ROUGE-2 : Precision:{scores['rouge-2']['p']}, Recall :{scores['rouge-2']['r']}, F1-Score:{scores['rouge-2']['f']}\")\n",
    "print(f\"ROUGE-l : Precision:{scores['rouge-l']['p']}, Recall :{scores['rouge-l']['r']}, F1-Score:{scores['rouge-l']['f']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
